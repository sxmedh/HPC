{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUqegLJD5VoF",
        "outputId": "3d5a13b7-5f36-47d8-fe93-51578321f914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvLbKC4i5VuW",
        "outputId": "574eb898-d572-44b0-f114-8d73a72dbb40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-x4d003i5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-x4d003i5\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/afnan47/cuda.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOBCsz7Q6ROy",
        "outputId": "0b09001e-3327-4223-9b93-1bdc43e771b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ2ust7K5V1a",
        "outputId": "2d2a1c43-dd64-4ab7-b1c1-48edeaf2c13c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector 1: \n",
            "0 2 8 18 32 \n",
            "Vector 2: \n",
            "0 1 2 3 4 \n",
            "Vector addition on GPU \n",
            "0 3 10 21 36 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include \"stdio.h\"\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Defining number of elements in Array\n",
        "#define N 5\n",
        "\n",
        "// Defining Kernel function for vector addition\n",
        "\n",
        "__global__ void gpuAdd(int *d_a, int *d_b, int *d_c)\n",
        "{\n",
        "    // Getting block index of current kernel\n",
        "    int tid = blockIdx.x; // handle the data at this index\n",
        "    if (tid < N)\n",
        "        d_c[tid] = d_a[tid] + d_b[tid];\n",
        "}\n",
        "\n",
        "// Main program\n",
        "int main(void)\n",
        "{\n",
        "    // Defining host arrays\n",
        "    int h_a[N], h_b[N], h_c[N];\n",
        "\n",
        "    // Defining device pointers\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    // allocate the memory\n",
        "    cudaMalloc((void**)&d_a, N * sizeof(int));\n",
        "    cudaMalloc((void**)&d_b, N * sizeof(int));\n",
        "    cudaMalloc((void**)&d_c, N * sizeof(int));\n",
        "\n",
        "    // Initializing Arrays\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_a[i] = 2*i*i;\n",
        "        h_b[i] = i ;\n",
        "    }\n",
        "\n",
        "    // Copy input arrays from host to device memory\n",
        "    cudaMemcpy(d_a, h_a, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Calling kernels with N blocks and one thread per block, passing\n",
        "    // device pointers as parameters\n",
        "    gpuAdd <<<N, 1 >>>(d_a, d_b, d_c);\n",
        "\n",
        "    // Copy result back to host memory from device memory\n",
        "    cudaMemcpy(h_c, d_c, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Vector 1: \\n\");\n",
        "    // Printing result on console\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        printf(\"%d \", h_a[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    printf(\"Vector 2: \\n\");\n",
        "    // Printing result on console\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        printf(\"%d \", h_b[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    printf(\"Vector addition on GPU \\n\");\n",
        "    // Printing result on console\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        printf(\"%d \", h_c[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // Free up memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EBwib3r76pSX"
      },
      "outputs": [],
      "source": [
        "%%cu\n",
        "#include \"stdio.h\"\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "_global_ void add(int* a, int* b, int* c) {\n",
        "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    c[i] = a[i] + b[i];\n",
        "}\n",
        "\n",
        "_managed_ int a[5], b[5], c[5];\n",
        "\n",
        "int main()\n",
        "{\n",
        "    const int arraySize = 5;\n",
        "    // Assign values to managed arrays directly\n",
        "    a[0] = 1; a[1] = 2; a[2] = 3; a[3] = 4; a[4] = 5;\n",
        "    b[0] = 10; b[1] = 20; b[2] = 30; b[3] = 40; b[4] = 50;\n",
        "    add << <1, 5 >> > (a, b, c);\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        printf(\"%d\\n\", c[i]);\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
