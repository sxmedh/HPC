{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPJerjGCF8Q6TFzeTGuExoT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NcMqtG9FaIEd","executionInfo":{"status":"ok","timestamp":1709488472713,"user_tz":-330,"elapsed":4,"user":{"displayName":"hardik kotangale","userId":"06213485721285416285"}},"outputId":"727d0c04-9b64-4bd5-c8b6-7835b39ebfb0"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"code","source":["!pip install git+https://github.com/afnan47/cuda.git\n","%load_ext nvcc_plugin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dXgiS0Dbci51","executionInfo":{"status":"ok","timestamp":1709488472713,"user_tz":-330,"elapsed":7800,"user":{"displayName":"hardik kotangale","userId":"06213485721285416285"}},"outputId":"be93cc63-01b8-4f48-e59a-8745346fb54d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/afnan47/cuda.git\n","  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-d222pajy\n","  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-d222pajy\n","  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: NVCCPlugin\n","  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4288 sha256=8a5da9f3ed490a14baa448e1c4c74bb37605cd9056d5d9895723ed4005662a2c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-uvh2146t/wheels/aa/f3/44/e10c1d226ec561d971fcd4b0463f6bff08602afa928a3e7bc7\n","Successfully built NVCCPlugin\n","Installing collected packages: NVCCPlugin\n","Successfully installed NVCCPlugin-0.0.2\n","created output directory at /content/src\n","Out bin /content/result.out\n"]}]},{"cell_type":"markdown","source":["# **Vector Addition**"],"metadata":{"id":"I7MM_Bi7ePZh"}},{"cell_type":"code","source":["%%cu\n","#include \"stdio.h\"\n","#include <iostream>\n","#include <cuda.h>\n","#include <cuda_runtime.h>\n","\n","// Defining number of elements in Array\n","#define N 5\n","\n","// Defining Kernel function for vector addition\n","__global__ void gpuAdd(int *d_a, int *d_b, int *d_c)\n","{\n","    // Getting block index of current kernel\n","    int tid = blockIdx.x; // handle the data at this index\n","    if (tid < N)\n","        d_c[tid] = d_a[tid] + d_b[tid];\n","}\n","// Main program\n","int main(void)\n","{\n","    // Defining host arrays\n","    int h_a[N], h_b[N], h_c[N];\n","    // Defining device pointers\n","    int *d_a, *d_b, *d_c;\n","    // allocate the memory\n","    cudaMalloc((void**)&d_a, N * sizeof(int));\n","    cudaMalloc((void**)&d_b, N * sizeof(int));\n","    cudaMalloc((void**)&d_c, N * sizeof(int));\n","    // Initializing Arrays\n","    for (int i = 0; i < N; i++) {\n","        h_a[i] = 2*i*i;\n","        h_b[i] = i ;\n","    }\n","\n","    // Copy input arrays from host to device memory\n","    cudaMemcpy(d_a, h_a, N * sizeof(int), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_b, h_b, N * sizeof(int), cudaMemcpyHostToDevice);\n","\n","    // Calling kernels with N blocks and one thread per block, passing\n","    // device pointers as parameters\n","    gpuAdd <<<N, 1 >>>(d_a, d_b, d_c);\n","\n","    // Copy result back to host memory from device memory\n","    cudaMemcpy(h_c, d_c, N * sizeof(int), cudaMemcpyDeviceToHost);\n","    printf(\"Vector addition on GPU \\n\");\n","\n","    // Printing result on console\n","    for (int i = 0; i < N; i++) {\n","        printf(\"The sum of %d element is %d + %d = %d\\n\",\n","            i, h_a[i], h_b[i],h_c[i]);\n","    }\n","    // Free up memory\n","    cudaFree(d_a);\n","    cudaFree(d_b);\n","    cudaFree(d_c);\n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QG6UTgzDcnxW","executionInfo":{"status":"ok","timestamp":1709488611162,"user_tz":-330,"elapsed":2421,"user":{"displayName":"hardik kotangale","userId":"06213485721285416285"}},"outputId":"c63f916d-7f77-4ae5-c7e4-2a5f24966701"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Vector addition on GPU \n","The sum of 0 element is 0 + 0 = 0\n","The sum of 1 element is 2 + 1 = 3\n","The sum of 2 element is 8 + 2 = 10\n","The sum of 3 element is 18 + 3 = 21\n","The sum of 4 element is 32 + 4 = 36\n","\n"]}]},{"cell_type":"markdown","source":["# **Matrix Multiplication**"],"metadata":{"id":"JJj_T1cneHyb"}},{"cell_type":"code","source":["%%cu\n","#include <iostream>\n","#include <cuda.h>\n","\n","using namespace std;\n","\n","#define BLOCK_SIZE 2\n","\n","__global__ void gpuMM(float *A, float *B, float *C, int N)\n","{\n","    // Matrix multiplication for NxN matrices C=A*B\n","    // Each thread computes a single element of C\n","    int row = blockIdx.y*blockDim.y + threadIdx.y;\n","    int col = blockIdx.x*blockDim.x + threadIdx.x;\n","\n","    float sum = 0.f;\n","    for (int n = 0; n < N; ++n)\n","        sum += A[row*N+n]*B[n*N+col];\n","\n","    C[row*N+col] = sum;\n","}\n","\n","int main(int argc, char *argv[])\n","{int N;float K;\n","    // Perform matrix multiplication C = A*B\n","    // where A, B and C are NxN matrices\n","    // Restricted to matrices where N = K*BLOCK_SIZE;\n","\tcout<<\"Enter a Value for Size/2 of matrix\";\n","\tcin>>K;\n","\n","    K = 1;\n","    N = K*BLOCK_SIZE;\n","\n","    cout << \"\\n Executing Matrix Multiplcation\" << endl;\n","    cout << \"\\n Matrix size: \" << N << \"x\" << N << endl;\n","\n","    // Allocate memory on the host\n","    float *hA,*hB,*hC;\n","    hA = new float[N*N];\n","    hB = new float[N*N];\n","    hC = new float[N*N];\n","\n","    // Initialize matrices on the host\n","    for (int j=0; j<N; j++){\n","        for (int i=0; i<N; i++){\n","           hA[j*N+i] = 2;\n","           hB[j*N+i] = 4;\n","\n","        }\n","    }\n","\n","    // Allocate memory on the device\n","    int size = N*N*sizeof(float);    // Size of the memory in bytes\n","    float *dA,*dB,*dC;\n","    cudaMalloc(&dA,size);\n","    cudaMalloc(&dB,size);\n","    cudaMalloc(&dC,size);\n","\n","    dim3 threadBlock(BLOCK_SIZE,BLOCK_SIZE);\n","    dim3 grid(K,K);\n","    cout<<\"\\n Input Matrix 1 \\n\";\n","    for (int row=0; row<N; row++){\n","            for (int col=0; col<N; col++){\n","\n","                   cout<<hA[row*col]<<\"\t\";\n","\n","            }\n","            cout<<endl;\n","        }\n","    cout<<\"\\n Input Matrix 2 \\n\";\n","    for (int row=0; row<N; row++){\n","            for (int col=0; col<N; col++){\n","\n","                   cout<<hB[row*col]<<\"\t\";\n","\n","            }\n","            cout<<endl;\n","        }\n","    // Copy matrices from the host to device\n","    cudaMemcpy(dA,hA,size,cudaMemcpyHostToDevice);\n","    cudaMemcpy(dB,hB,size,cudaMemcpyHostToDevice);\n","\n","    //Execute the matrix multiplication kernel\n","\n","    gpuMM<<<grid,threadBlock>>>(dA,dB,dC,N);\n","\n","    // Now do the matrix multiplication on the CPU\n","   /*float sum;\n","    for (int row=0; row<N; row++){\n","        for (int col=0; col<N; col++){\n","            sum = 0.f;\n","            for (int n=0; n<N; n++){\n","                sum += hA[row*N+n]*hB[n*N+col];\n","            }\n","            hC[row*N+col] = sum;\n","            cout << sum <<\"\t\";\n","\n","\n","        }\n","        cout<<endl;\n","    }*/\n","\n","    // Allocate memory to store the GPU answer on the host\n","    float *C;\n","    C = new float[N*N];\n","\n","    // Now copy the GPU result back to CPU\n","    cudaMemcpy(C,dC,size,cudaMemcpyDeviceToHost);\n","\n","    // Check the result and make sure it is correct\n","    cout <<\"\\n\\n\\n\\n\\n Resultant matrix\\n\\n\";\n","    for (int row=0; row<N; row++){\n","        for (int col=0; col<N; col++){\n","\n","               cout<<C[row*col]<<\"\t\";\n","\n","        }\n","        cout<<endl;\n","    }\n","\n","    cout << \"Finished.\" << endl;\n","}"],"metadata":{"id":"6e4eIAIBc_nU","executionInfo":{"status":"ok","timestamp":1709488754947,"user_tz":-330,"elapsed":1909,"user":{"displayName":"hardik kotangale","userId":"06213485721285416285"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa5e87bc-b8cd-4a85-86b0-b5bf6fff55a9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter a Value for Size/2 of matrix\n"," Executing Matrix Multiplcation\n","\n"," Matrix size: 2x2\n","\n"," Input Matrix 1 \n","2\t2\t\n","2\t2\t\n","\n"," Input Matrix 2 \n","4\t4\t\n","4\t4\t\n","\n","\n","\n","\n","\n"," Resultant matrix\n","\n","16\t16\t\n","16\t16\t\n","Finished.\n","\n"]}]}]}