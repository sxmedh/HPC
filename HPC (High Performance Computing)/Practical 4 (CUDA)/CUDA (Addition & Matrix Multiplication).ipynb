{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1709488472713,
     "user": {
      "displayName": "hardik kotangale",
      "userId": "06213485721285416285"
     },
     "user_tz": -330
    },
    "id": "NcMqtG9FaIEd",
    "outputId": "727d0c04-9b64-4bd5-c8b6-7835b39ebfb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvcc\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7800,
     "status": "ok",
     "timestamp": 1709488472713,
     "user": {
      "displayName": "hardik kotangale",
      "userId": "06213485721285416285"
     },
     "user_tz": -330
    },
    "id": "dXgiS0Dbci51",
    "outputId": "be93cc63-01b8-4f48-e59a-8745346fb54d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/afnan47/cuda.git\n",
      "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-vsbv120z\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-vsbv120z\n",
      "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: NVCCPlugin\n",
      "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4306 sha256=ce68a175d1a867ca8e4be0eecb0f59bc0070324c30d17b1932c900cf4d374939\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-aqifizfo/wheels/aa/f3/44/e10c1d226ec561d971fcd4b0463f6bff08602afa928a3e7bc7\n",
      "Successfully built NVCCPlugin\n",
      "Installing collected packages: NVCCPlugin\n",
      "Successfully installed NVCCPlugin-0.0.2\n",
      "created output directory at /home/sumedh/zNotes/Engineering_Notes/BE/HPC/HPC (High Performance Computing)/Practical 4 (CUDA)/src\n",
      "Out bin /home/sumedh/zNotes/Engineering_Notes/BE/HPC/HPC (High Performance Computing)/Practical 4 (CUDA)/result.out\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/afnan47/cuda.git\n",
    "%load_ext nvcc_plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7MM_Bi7ePZh"
   },
   "source": [
    "# **Vector Addition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2421,
     "status": "ok",
     "timestamp": 1709488611162,
     "user": {
      "displayName": "hardik kotangale",
      "userId": "06213485721285416285"
     },
     "user_tz": -330
    },
    "id": "QG6UTgzDcnxW",
    "outputId": "c63f916d-7f77-4ae5-c7e4-2a5f24966701"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/usr/local/cuda/bin/nvcc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m#include \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstdio.h\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m#include <iostream>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m#include <cuda.h>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m#include <cuda_runtime.h>\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m// Defining number of elements in Array\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m#define N 5\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m// Defining Kernel function for vector addition\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m__global__ void gpuAdd(int *d_a, int *d_b, int *d_c)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    // Getting block index of current kernel\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    int tid = blockIdx.x; // handle the data at this index\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    if (tid < N)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        d_c[tid] = d_a[tid] + d_b[tid];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m// Main program\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mint main(void)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    // Defining host arrays\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    int h_a[N], h_b[N], h_c[N];\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    // Defining device pointers\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    int *d_a, *d_b, *d_c;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    // allocate the memory\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    cudaMalloc((void**)&d_a, N * sizeof(int));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    cudaMalloc((void**)&d_b, N * sizeof(int));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    cudaMalloc((void**)&d_c, N * sizeof(int));\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    // Initializing Arrays\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    for (int i = 0; i < N; i++) \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        h_a[i] = 2*i*i;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        h_b[i] = i ;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    // Copy input arrays from host to device memory\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    cudaMemcpy(d_a, h_a, N * sizeof(int), cudaMemcpyHostToDevice);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    cudaMemcpy(d_b, h_b, N * sizeof(int), cudaMemcpyHostToDevice);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    // Calling kernels with N blocks and one thread per block, passing\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    // device pointers as parameters\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    gpuAdd <<<N, 1 >>>(d_a, d_b, d_c);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    // Copy result back to host memory from device memory\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    cudaMemcpy(h_c, d_c, N * sizeof(int), cudaMemcpyDeviceToHost);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    printf(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVector addition on GPU \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    // Printing result on console\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    for (int i = 0; i < N; i++) \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        printf(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe sum of \u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m element is \u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m + \u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m = \u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m            i, h_a[i], h_b[i],h_c[i]);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    }\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    // Free up memory\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    cudaFree(d_a);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    cudaFree(d_b);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    cudaFree(d_c);\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    return 0;\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m}\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2541\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2539\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2540\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/v1/v1.py:52\u001b[0m, in \u001b[0;36mNVCCPlugin.cu\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m     50\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(cell)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(file_path, timeit\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtimeit)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/v1/v1.py:23\u001b[0m, in \u001b[0;36mNVCCPlugin.compile\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(file_path):\n\u001b[0;32m---> 23\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcompiler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.out\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-Wno-deprecated-gpu-targets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTDOUT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:421\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    419\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[0;32m--> 421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    501\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/local/cuda/bin/nvcc'"
     ]
    }
   ],
   "source": [
    "%%cu\n",
    "#include \"stdio.h\"\n",
    "#include <iostream>\n",
    "#include <cuda.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "// Defining number of elements in Array\n",
    "#define N 5\n",
    "\n",
    "// Defining Kernel function for vector addition\n",
    "__global__ void gpuAdd(int *d_a, int *d_b, int *d_c)\n",
    "{\n",
    "    // Getting block index of current kernel\n",
    "    int tid = blockIdx.x; // handle the data at this index\n",
    "    if (tid < N)\n",
    "        d_c[tid] = d_a[tid] + d_b[tid];\n",
    "}\n",
    "// Main program\n",
    "int main(void)\n",
    "{\n",
    "    // Defining host arrays\n",
    "    int h_a[N], h_b[N], h_c[N];\n",
    "    // Defining device pointers\n",
    "    int *d_a, *d_b, *d_c;\n",
    "    // allocate the memory\n",
    "    cudaMalloc((void**)&d_a, N * sizeof(int));\n",
    "    cudaMalloc((void**)&d_b, N * sizeof(int));\n",
    "    cudaMalloc((void**)&d_c, N * sizeof(int));\n",
    "    // Initializing Arrays\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        h_a[i] = 2*i*i;\n",
    "        h_b[i] = i ;\n",
    "    }\n",
    "\n",
    "    // Copy input arrays from host to device memory\n",
    "    cudaMemcpy(d_a, h_a, N * sizeof(int), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, N * sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Calling kernels with N blocks and one thread per block, passing\n",
    "    // device pointers as parameters\n",
    "    gpuAdd <<<N, 1 >>>(d_a, d_b, d_c);\n",
    "\n",
    "    // Copy result back to host memory from device memory\n",
    "    cudaMemcpy(h_c, d_c, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    printf(\"Vector addition on GPU \\n\");\n",
    "\n",
    "    // Printing result on console\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        printf(\"The sum of %d element is %d + %d = %d\\n\",\n",
    "            i, h_a[i], h_b[i],h_c[i]);\n",
    "    }\n",
    "    // Free up memory\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJj_T1cneHyb"
   },
   "source": [
    "# **Matrix Multiplication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1909,
     "status": "ok",
     "timestamp": 1709488754947,
     "user": {
      "displayName": "hardik kotangale",
      "userId": "06213485721285416285"
     },
     "user_tz": -330
    },
    "id": "6e4eIAIBc_nU",
    "outputId": "fa5e87bc-b8cd-4a85-86b0-b5bf6fff55a9"
   },
   "outputs": [],
   "source": [
    "%%cu\n",
    "#include <iostream>\n",
    "#include <cuda.h>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "#define BLOCK_SIZE 2\n",
    "\n",
    "__global__ void gpuMM(float *A, float *B, float *C, int N)\n",
    "{\n",
    "    // Matrix multiplication for NxN matrices C=A*B\n",
    "    // Each thread computes a single element of C\n",
    "    int row = blockIdx.y*blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "\n",
    "    float sum = 0.f;\n",
    "    for (int n = 0; n < N; ++n)\n",
    "        sum += A[row*N+n]*B[n*N+col];\n",
    "\n",
    "    C[row*N+col] = sum;\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[])\n",
    "{int N;float K;\n",
    "    // Perform matrix multiplication C = A*B\n",
    "    // where A, B and C are NxN matrices\n",
    "    // Restricted to matrices where N = K*BLOCK_SIZE;\n",
    "\tcout<<\"Enter a Value for Size/2 of matrix\";\n",
    "\tcin>>K;\n",
    "\n",
    "    K = 1;\n",
    "    N = K*BLOCK_SIZE;\n",
    "\n",
    "    cout << \"\\n Executing Matrix Multiplcation\" << endl;\n",
    "    cout << \"\\n Matrix size: \" << N << \"x\" << N << endl;\n",
    "\n",
    "    // Allocate memory on the host\n",
    "    float *hA,*hB,*hC;\n",
    "    hA = new float[N*N];\n",
    "    hB = new float[N*N];\n",
    "    hC = new float[N*N];\n",
    "\n",
    "    // Initialize matrices on the host\n",
    "    for (int j=0; j<N; j++){\n",
    "        for (int i=0; i<N; i++){\n",
    "           hA[j*N+i] = 2;\n",
    "           hB[j*N+i] = 4;\n",
    "\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Allocate memory on the device\n",
    "    int size = N*N*sizeof(float);    // Size of the memory in bytes\n",
    "    float *dA,*dB,*dC;\n",
    "    cudaMalloc(&dA,size);\n",
    "    cudaMalloc(&dB,size);\n",
    "    cudaMalloc(&dC,size);\n",
    "\n",
    "    dim3 threadBlock(BLOCK_SIZE,BLOCK_SIZE);\n",
    "    dim3 grid(K,K);\n",
    "    cout<<\"\\n Input Matrix 1 \\n\";\n",
    "    for (int row=0; row<N; row++){\n",
    "            for (int col=0; col<N; col++){\n",
    "\n",
    "                   cout<<hA[row*col]<<\"\t\";\n",
    "\n",
    "            }\n",
    "            cout<<endl;\n",
    "        }\n",
    "    cout<<\"\\n Input Matrix 2 \\n\";\n",
    "    for (int row=0; row<N; row++){\n",
    "            for (int col=0; col<N; col++){\n",
    "\n",
    "                   cout<<hB[row*col]<<\"\t\";\n",
    "\n",
    "            }\n",
    "            cout<<endl;\n",
    "        }\n",
    "    // Copy matrices from the host to device\n",
    "    cudaMemcpy(dA,hA,size,cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(dB,hB,size,cudaMemcpyHostToDevice);\n",
    "\n",
    "    //Execute the matrix multiplication kernel\n",
    "\n",
    "    gpuMM<<<grid,threadBlock>>>(dA,dB,dC,N);\n",
    "\n",
    "    // Now do the matrix multiplication on the CPU\n",
    "   /*float sum;\n",
    "    for (int row=0; row<N; row++){\n",
    "        for (int col=0; col<N; col++){\n",
    "            sum = 0.f;\n",
    "            for (int n=0; n<N; n++){\n",
    "                sum += hA[row*N+n]*hB[n*N+col];\n",
    "            }\n",
    "            hC[row*N+col] = sum;\n",
    "            cout << sum <<\"\t\";\n",
    "\n",
    "\n",
    "        }\n",
    "        cout<<endl;\n",
    "    }*/\n",
    "\n",
    "    // Allocate memory to store the GPU answer on the host\n",
    "    float *C;\n",
    "    C = new float[N*N];\n",
    "\n",
    "    // Now copy the GPU result back to CPU\n",
    "    cudaMemcpy(C,dC,size,cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Check the result and make sure it is correct\n",
    "    cout <<\"\\n\\n\\n\\n\\n Resultant matrix\\n\\n\";\n",
    "    for (int row=0; row<N; row++){\n",
    "        for (int col=0; col<N; col++){\n",
    "\n",
    "               cout<<C[row*col]<<\"\t\";\n",
    "\n",
    "        }\n",
    "        cout<<endl;\n",
    "    }\n",
    "\n",
    "    cout << \"Finished.\" << endl;\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPJerjGCF8Q6TFzeTGuExoT",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
